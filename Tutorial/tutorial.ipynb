{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb16d6b-b21b-45de-945c-40be3379c680",
   "metadata": {},
   "source": [
    "CSC480 Assignment 1 tutorial\n",
    "Damien Trunkey, Emily Lucas, Sophia Parrett, Fernando Valdivia, Divya Satrawada, Rey Ortiz\n",
    "Social Justice League!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eabe39-5cfb-4b20-98bb-589681a026dc",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "    \n",
    "This is a tutorial on how to preprocess data to make it ready to train a model. \n",
    "\n",
    "You can get data many ways. You can use [webscraping](https://realpython.com/python-web-scraping-practical-introduction/#reader-comments), you can get a dataset from [kaggle datasets](https://www.kaggle.com/datasets), or you can get data using an api that has access to  lots of data. We chose to use the Reddit.com api to get data from the reddit.com forums. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9d883-78e7-419d-837b-5902ba75367c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We are using pandas and numpy, which are two data science libraries in python. The pandas import alows us to create data frames (matrices) and numpy lets us do many mathematical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b96d4e-865d-4b67-9515-31c06f7d3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70034749-18ff-4598-a107-565843045cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    14569\n",
      "3     3022\n",
      "4     3507\n",
      "5     1835\n",
      "6    11710\n",
      "Name: ups, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello.\\r\\n\\r\\nI am one of the many in the midw...</td>\n",
       "      <td>14569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I (31f) married my husband (35m) when I gradua...</td>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r\\nI am a college student and in high school ...</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\r\\n\\r\\nI (29F) got set up (again) for a blind...</td>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My wife (39F) and I (36M) got married and move...</td>\n",
       "      <td>11710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext    ups\n",
       "2  Hello.\\r\\n\\r\\nI am one of the many in the midw...  14569\n",
       "3  I (31f) married my husband (35m) when I gradua...   3022\n",
       "4  \\r\\nI am a college student and in high school ...   3507\n",
       "5  \\r\\n\\r\\nI (29F) got set up (again) for a blind...   1835\n",
       "6  My wife (39F) and I (36M) got married and move...  11710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the data into a dataframe to manupulate and do preprocessing\n",
    "dataFile = 'AmItheAsshole_subreddit.csv'\n",
    "df = pd.read_csv(dataFile)\n",
    "df = df.head(7)\n",
    "df = df[['selftext', 'ups']]\n",
    "df = df[2:7]\n",
    "ground_truth = df['ups']\n",
    "print(ground_truth)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2265d11-49c9-4992-9ae5-0a244dd9ea7b",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalization is the process of simplifying text in order to make it easier to work with. This is achieved by multiple steps. To begin with, change all of the words with the lower-case version of themselves using .lower(). This is needed because words such as \"They\" and \"they\" would be counted as two different words. However, these should be counted as the same word, so .lower() is used to normalize the capitalization of the text. \n",
    "\n",
    "After all the words are changed to lower-case, the next step is to replace all non-alphanumeric characters with whitespace. This is achieved by utilizing the .replace(\"[^\\w\\s]\", \" \") method. This would eliminate all punctuation, as well as any additional spaces, tabs, or newlines between words and replace it with whitespace. [^\\w\\s] is a regular expression that is used to capture all non-alphanumeric words. Once again, this is needed because punctuation is irrelevant when it comes to natural language processing and elimination it would further simplify the text. \n",
    "\n",
    "Additionally, replacing everything with whitespaces is needed for the final step, which is to split the text on whitespace. This is achieved by utilizing .split(). This method takes the string of text and turns it into a list of separate words. It does this by going through each letter of the string and anytime a whitespace is found, the previous grouping of letters is taken and inserted into a list as one element. To summarize, the steps of normalization are taking the string and applying .lower(), .replace(\"[^\\w\\s]\", \" \"), and finally utilizing .split(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93b0c41-61b0-4fcb-8677-b226faac6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = (\n",
    "    df['selftext'].\n",
    "    str.lower().                  # convert all letters to lowercase\n",
    "    str.replace(\"[^\\w\\s]\", \" \", regex=True).  # replace non-alphanumeric characters by whitespace\n",
    "    str.split()                   # split on whitespace\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf6c80d-ec89-4c5e-8b32-72fc1e6e49c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hello</th>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <th>one</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>many</th>\n",
       "      <th>in</th>\n",
       "      <th>midwest</th>\n",
       "      <th>hit</th>\n",
       "      <th>...</th>\n",
       "      <th>respects</th>\n",
       "      <th>admires</th>\n",
       "      <th>okay</th>\n",
       "      <th>feels</th>\n",
       "      <th>berate</th>\n",
       "      <th>allowing</th>\n",
       "      <th>happen</th>\n",
       "      <th>rebuild</th>\n",
       "      <th>boundaries</th>\n",
       "      <th>ashamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 775 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hello   i   am  one  of  the  many  in  midwest  hit  ...  respects  \\\n",
       "2    1.0  40  2.0  2.0  13   14   1.0   5      1.0  1.0  ...       0.0   \n",
       "3    0.0  27  2.0  0.0   6   12   0.0  13      0.0  0.0  ...       0.0   \n",
       "4    0.0  65  1.0  1.0   7   14   2.0  16      0.0  0.0  ...       0.0   \n",
       "5    0.0  20  0.0  1.0   3    8   0.0   1      0.0  0.0  ...       0.0   \n",
       "6    0.0  21  0.0  0.0  10   12   0.0   7      0.0  0.0  ...       1.0   \n",
       "\n",
       "   admires  okay  feels  berate  allowing  happen  rebuild  boundaries  \\\n",
       "2      0.0   0.0    0.0     0.0       0.0     0.0      0.0         0.0   \n",
       "3      0.0   0.0    0.0     0.0       0.0     0.0      0.0         0.0   \n",
       "4      0.0   0.0    0.0     0.0       0.0     0.0      0.0         0.0   \n",
       "5      0.0   0.0    0.0     0.0       0.0     0.0      0.0         0.0   \n",
       "6      1.0   1.0    1.0     1.0       1.0     1.0      1.0         1.0   \n",
       "\n",
       "   ashamed  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      1.0  \n",
       "\n",
       "[5 rows x 775 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'hello': 1, 'i': 40, 'am': 2, 'one': 2, 'of':...</td>\n",
       "      <td>14569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'i': 27, '31f': 1, 'married': 1, 'my': 22, 'h...</td>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'i': 65, 'am': 1, 'a': 17, 'college': 6, 'stu...</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'i': 20, '29f': 1, 'got': 5, 'set': 1, 'up': ...</td>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'my': 8, 'wife': 4, '39f': 1, 'and': 17, 'i':...</td>\n",
       "      <td>11710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext    ups\n",
       "2  {'hello': 1, 'i': 40, 'am': 2, 'one': 2, 'of':...  14569\n",
       "3  {'i': 27, '31f': 1, 'married': 1, 'my': 22, 'h...   3022\n",
       "4  {'i': 65, 'am': 1, 'a': 17, 'college': 6, 'stu...   3507\n",
       "5  {'i': 20, '29f': 1, 'got': 5, 'set': 1, 'up': ...   1835\n",
       "6  {'my': 8, 'wife': 4, '39f': 1, 'and': 17, 'i':...  11710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Getting raw frequency to turn into tf-idf vectors\n",
    "raw_frequency = bag_of_words.apply(Counter)\n",
    "\n",
    "df['selftext'] = raw_frequency\n",
    "\n",
    "tf = pd.DataFrame(list(raw_frequency),index=raw_frequency.index)\n",
    "columns = list(tf.columns)\n",
    "tf = tf.fillna(0)\n",
    "display(tf)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa71dc-ec72-4998-b237-c29f176a3d62",
   "metadata": {},
   "source": [
    "## Remove Stop Words \n",
    "Next in this tutorial we will remove stop words. Removing stop words is important because it gets rid of trivial words (like \"a\", \"the\" etc.), and focuses on more important information. Words that are kept are more topical, and have a stronger connotation. This can be done by creating a list of stop words (from 'stopwords-short.txt') and removing columns in our dataframe that contain stop words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b1142a-a37d-46f2-950b-b2e6e425359c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hello</th>\n",
       "      <th>am</th>\n",
       "      <th>one</th>\n",
       "      <th>many</th>\n",
       "      <th>midwest</th>\n",
       "      <th>hit</th>\n",
       "      <th>snowpocolypse</th>\n",
       "      <th>think</th>\n",
       "      <th>we</th>\n",
       "      <th>got</th>\n",
       "      <th>...</th>\n",
       "      <th>respects</th>\n",
       "      <th>admires</th>\n",
       "      <th>okay</th>\n",
       "      <th>feels</th>\n",
       "      <th>berate</th>\n",
       "      <th>allowing</th>\n",
       "      <th>happen</th>\n",
       "      <th>rebuild</th>\n",
       "      <th>boundaries</th>\n",
       "      <th>ashamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 746 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hello   am  one  many  midwest  hit  snowpocolypse  think  we  got  ...  \\\n",
       "2    1.0  2.0  2.0   1.0      1.0  1.0            1.0    1.0   3  2.0  ...   \n",
       "3    0.0  2.0  0.0   0.0      0.0  0.0            0.0    0.0   4  3.0  ...   \n",
       "4    0.0  1.0  1.0   2.0      0.0  0.0            0.0    0.0   4  0.0  ...   \n",
       "5    0.0  0.0  1.0   0.0      0.0  0.0            0.0    1.0   3  5.0  ...   \n",
       "6    0.0  0.0  0.0   0.0      0.0  0.0            0.0    0.0   3  1.0  ...   \n",
       "\n",
       "   respects  admires  okay  feels  berate  allowing  happen  rebuild  \\\n",
       "2       0.0      0.0   0.0    0.0     0.0       0.0     0.0      0.0   \n",
       "3       0.0      0.0   0.0    0.0     0.0       0.0     0.0      0.0   \n",
       "4       0.0      0.0   0.0    0.0     0.0       0.0     0.0      0.0   \n",
       "5       0.0      0.0   0.0    0.0     0.0       0.0     0.0      0.0   \n",
       "6       1.0      1.0   1.0    1.0     1.0       1.0     1.0      1.0   \n",
       "\n",
       "   boundaries  ashamed  \n",
       "2         0.0      0.0  \n",
       "3         0.0      0.0  \n",
       "4         0.0      0.0  \n",
       "5         0.0      0.0  \n",
       "6         1.0      1.0  \n",
       "\n",
       "[5 rows x 746 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopFile = 'stopwords-short.txt'\n",
    "f = open(stopFile, \"r\")\n",
    "stop_words = []\n",
    "for line in f:\n",
    "    words = line.split(',')\n",
    "for word in words:\n",
    "    word = word.replace('\"', \"\").strip(\" \").lower()\n",
    "    stop_words.append(word)\n",
    "    \n",
    "for col in columns:\n",
    "    if col in stop_words:\n",
    "        tf = tf.drop([col], axis=1)\n",
    "display(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47554ea-b557-470f-a852-72327d975096",
   "metadata": {},
   "source": [
    "## TF-IDF Vectors\n",
    "\n",
    "TF-IDF stands for term frequency-inverse document frequency and it is a measure to quantify  how important certain terms are throughout a list of documents (corpus). \n",
    "Term frequency (TF) is the measure of how often a word appears in a single document and inverse document frequency (IDF) is the measure of how common or uncommon a term is throughout the corpus. If a word appears in only two documents, then it may be considered rare, therefore it carries more importance. The equation to find IDF follows the form where t is the term and D is the corpus and d is the current document and N is the number of documents:\n",
    "idf(t,D) = log(N / count(d D; t  D))\n",
    "IDF is important because it takes common words in the English language and weights them less, giving less common words more impact.\n",
    "When we put TF and IDF together we can show that a term is inversely related to its frequency across documents. By multiplying these together we can get the final TF-IDF value. Higher values means a term holds more importance and closer to 0 means it's less relevant.\n",
    "ifidf(t,d,D) = tf(t,d) * idf(t,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683b5276-b5d2-4e79-a616-cd673ac8d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hello</th>\n",
       "      <th>am</th>\n",
       "      <th>one</th>\n",
       "      <th>many</th>\n",
       "      <th>midwest</th>\n",
       "      <th>hit</th>\n",
       "      <th>snowpocolypse</th>\n",
       "      <th>think</th>\n",
       "      <th>we</th>\n",
       "      <th>got</th>\n",
       "      <th>...</th>\n",
       "      <th>respects</th>\n",
       "      <th>admires</th>\n",
       "      <th>okay</th>\n",
       "      <th>feels</th>\n",
       "      <th>berate</th>\n",
       "      <th>allowing</th>\n",
       "      <th>happen</th>\n",
       "      <th>rebuild</th>\n",
       "      <th>boundaries</th>\n",
       "      <th>ashamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.021651</td>\n",
       "      <td>1.021651</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.021651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.115718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 746 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hello        am       one      many   midwest       hit  snowpocolypse  \\\n",
       "2  1.609438  1.021651  1.021651  0.916291  1.609438  1.609438       1.609438   \n",
       "3  0.000000  1.021651  0.000000  0.000000  0.000000  0.000000       0.000000   \n",
       "4  0.000000  0.510826  0.510826  1.832581  0.000000  0.000000       0.000000   \n",
       "5  0.000000  0.000000  0.510826  0.000000  0.000000  0.000000       0.000000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000       0.000000   \n",
       "\n",
       "      think   we       got  ...  respects   admires      okay     feels  \\\n",
       "2  0.916291  0.0  0.446287  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.0  0.669431  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.0  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.916291  0.0  1.115718  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.0  0.223144  ...  1.609438  1.609438  1.609438  1.609438   \n",
       "\n",
       "     berate  allowing    happen   rebuild  boundaries   ashamed  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000  \n",
       "6  1.609438  1.609438  1.609438  1.609438    1.609438  1.609438  \n",
       "\n",
       "[5 rows x 746 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get document frequencies \n",
    "# (How many documents does each word appear in?)\n",
    "df = (tf > 0).sum(axis=0)\n",
    "\n",
    "# Get IDFs\n",
    "idf = np.log(len(tf) / df)\n",
    "idf.sort_values()\n",
    "\n",
    "# Calculate TF-IDFs\n",
    "tf_idf = tf * idf\n",
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a82f67-4fbd-4820-8502-25cb615e89c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
